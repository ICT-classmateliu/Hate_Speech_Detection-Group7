import json
import joblib
import torch
import numpy as np
import pandas as pd
import gradio as gr
import os
import re
import string
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px

# artifacts path (created by training script)
ARTIFACTS_DIR = os.path.join('main', 'artifacts')

# Global variables for lazy loading
model = None
scaler = None
base_scaler = None
feature_columns = None
label_map = None
optimal_thresholds = None
artifacts_loaded = False

# æ¨ç†ç»“æœç¼“å­˜ï¼ˆé¿å…é‡å¤è®¡ç®—ç›¸åŒå¥å­ï¼‰
prediction_cache = {}
CACHE_MAX_SIZE = 100  # æœ€å¤šç¼“å­˜100ä¸ªå¥å­

def load_artifacts():
    """
    å¯åŠ¨æ—¶åŠ è½½ artifactsï¼Œç¡®ä¿æ¨¡å‹å¯ç”¨
    """
    global model, scaler, base_scaler, feature_columns, label_map, artifacts_loaded

    if artifacts_loaded:
        return  # å·²åŠ è½½ï¼Œç›´æ¥è¿”å›

    print("æ­£åœ¨åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†å™¨...")

    model_path = os.path.join(ARTIFACTS_DIR, 'final_model_state_dict.pth')
    scaler_path = os.path.join(ARTIFACTS_DIR, 'scaler.pkl')
    cols_path = os.path.join(ARTIFACTS_DIR, 'feature_columns.json')
    labels_path = os.path.join(ARTIFACTS_DIR, 'label_map.json')
    base_scaler_path = os.path.join(ARTIFACTS_DIR, 'base_scaler.pkl')

    # æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_files = []
    if not os.path.exists(model_path):
        missing_files.append('final_model_state_dict.pth')
    if not os.path.exists(scaler_path):
        missing_files.append('scaler.pkl')
    if not os.path.exists(cols_path):
        missing_files.append('feature_columns.json')
    if not os.path.exists(labels_path):
        missing_files.append('label_map.json')
    # é˜ˆå€¼æ–‡ä»¶æ˜¯å¯é€‰çš„ï¼Œå¦‚æœæ²¡æœ‰å°±ä½¿ç”¨é»˜è®¤é˜ˆå€¼

    if missing_files:
        raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦çš„artifactsæ–‡ä»¶: {', '.join(missing_files)}. è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python main/train_final_model.py")

    # åŠ è½½æ¨¡å‹æƒé‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_state = torch.load(model_path, map_location=device, weights_only=True)
    scaler = joblib.load(scaler_path)
    base_scaler = joblib.load(base_scaler_path) if os.path.exists(base_scaler_path) else None

    # åŠ è½½é…ç½®æ–‡ä»¶
    with open(cols_path, 'r', encoding='utf-8') as f:
        feature_columns = json.load(f)
    with open(labels_path, 'r', encoding='utf-8') as f:
        label_map = json.load(f)

    # æ„å»ºæ¨¡å‹
    input_dim = len(feature_columns)
    model = MLPNet(input_dim=input_dim, hidden_dims=[80, 40, 40, 10], num_classes=len(label_map))
    model.load_state_dict(model_state)
    model.to(device)
    model.eval()

    artifacts_loaded = True
    print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼ç‰¹å¾ç»´åº¦: {input_dim}")
    return model, scaler, base_scaler, feature_columns, label_map

# Optimized feature extraction for fast demo purposes
def extract_basic_features(sentence: str, feature_columns):
    """
    å¿«é€Ÿç‰¹å¾æå– - ä¸è®­ç»ƒæ—¶ç‰¹å¾å®Œå…¨åŒ¹é…
    """
    # Clean the text but keep more information for hate speech detection
    sentence = sentence.lower()
    # ç§»é™¤URLå’Œ@mentionsï¼Œç„¶åç§»é™¤æ ‡ç‚¹ç¬¦å·ä½†ä¿ç•™å­—æ¯å’Œæ•°å­—
    clean_text = re.sub(r"(\w+:\/\/\S+)|(@[A-Za-z0-9]+)", " ", sentence)
    clean_text = re.sub(r"[^a-zA-Z0-9\s]", "", clean_text)  # ç§»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
    clean_text = ' '.join(clean_text.split())

    # Basic sentiment features
    words = clean_text.split()
    word_count = max(len(words), 1)  # é¿å…é™¤é›¶

    # åŠ è½½å¤–éƒ¨è¯å…¸
    hate_words, neg_words, pos_words, ngram_hate_scores = load_external_dictionaries()

    # å¿«é€Ÿè®¡æ•°
    hate_count = sum(1 for word in words if word in hate_words)
    neg_count = sum(1 for word in words if word in neg_words)
    pos_count = sum(1 for word in words if word in pos_words)

    # è®¡ç®—ä»‡æ¨è¨€è®ºå¼ºåº¦æŒ‡æ ‡
    hate_intensity = 0
    if hate_count > 0:
        hate_intensity = hate_count / word_count
        # å¦‚æœåŒ…å«ç§æ—/æ€§åˆ«æ­§è§†è¯ï¼Œå¢åŠ æƒé‡
        racial_words = {'nigger', 'kike', 'chink', 'gook', 'spic', 'wetback', 'coon', 'paki', 'raghead', 'towelhead'}
        gender_words = {'faggot', 'dyke', 'tranny', 'shemale', 'whore', 'slut'}
        violence_words = {'kill', 'die', 'death', 'murder', 'rape', 'torture'}

        racial_count = sum(1 for word in words if word in racial_words)
        gender_count = sum(1 for word in words if word in gender_words)
        violence_count = sum(1 for word in words if word in violence_words)

        if racial_count > 0:
            hate_intensity *= 2.0  # ç§æ—æ­§è§†æƒé‡æ›´é«˜
        if gender_count > 0:
            hate_intensity *= 1.8  # æ€§åˆ«æ­§è§†æƒé‡
        if violence_count > 0:
            hate_intensity *= 1.5  # æš´åŠ›ç›¸å…³æƒé‡

    # æ ¹æ®feature_columns.jsonçš„å®é™…ç»“æ„åˆ›å»ºç‰¹å¾å‘é‡
    # æ€»å…±1687ä¸ªç‰¹å¾ï¼Œæ‰€æœ‰æ— æ³•è®¡ç®—çš„å¤æ‚ç‰¹å¾éƒ½è®¾ä¸º0
    features = []

    # 1. weighted_TFIDF_scores (ä½¿ç”¨ä»‡æ¨å¼ºåº¦è¿‘ä¼¼)
    features.append(hate_intensity)

    # 2. sentiment features (6ä¸ª)
    features.extend([
        hate_count,  # sentiment:hate
        hate_intensity,  # sentiment:hatenor (ä½¿ç”¨å¢å¼ºçš„ä»‡æ¨å¼ºåº¦)
        neg_count,   # sentiment:neg
        neg_count / word_count if word_count > 0 else 0,  # sentiment:negnor
        pos_count,   # sentiment:pos
        pos_count / word_count if word_count > 0 else 0,  # sentiment:posnor
    ])

    # 3. dependency features (40ä¸ªï¼Œè®¾ä¸º0)
    features.extend([0] * 40)

    # 4. char_bigrams (984ä¸ªï¼Œè®¾ä¸º0)
    features.extend([0] * 984)

    # 5. word_bigrams (101ä¸ªï¼Œè®¾ä¸º0)
    features.extend([0] * 101)

    # 6. tfidf features (555ä¸ªï¼Œä½¿ç”¨ä»‡æ¨è¯å¯†åº¦è¿‘ä¼¼)
    # è¿™æ˜¯ç®€åŒ–çš„è¿‘ä¼¼ï¼Œæ‰€æœ‰TF-IDFç‰¹å¾éƒ½è®¾ä¸ºç›¸åŒçš„ä»‡æ¨è¯å¯†åº¦å€¼
    features.extend([hate_count / word_count if word_count > 0 else 0] * 555)

    return np.array(features).reshape(1, -1)

def predict_with_optimized_thresholds(sample_probs, thresholds):
    """
    ä½¿ç”¨ä¼˜åŒ–çš„é˜ˆå€¼è¿›è¡Œå•æ ·æœ¬é¢„æµ‹
    """
    n_classes = len(sample_probs)

    # æ£€æŸ¥æ¯ä¸ªç±»åˆ«æ˜¯å¦è¶…è¿‡å…¶é˜ˆå€¼
    valid_classes = []
    for class_idx in range(n_classes):
        threshold = thresholds[str(class_idx)]['threshold']
        if sample_probs[class_idx] >= threshold:
            valid_classes.append((class_idx, sample_probs[class_idx]))

    if valid_classes:
        # å¦‚æœæœ‰å¤šä¸ªç±»åˆ«è¶…è¿‡é˜ˆå€¼ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„
        valid_classes.sort(key=lambda x: x[1], reverse=True)
        return valid_classes[0][0]
    else:
        # å¦‚æœæ²¡æœ‰ç±»åˆ«è¶…è¿‡é˜ˆå€¼ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ï¼ˆå…œåº•ç­–ç•¥ï¼‰
        return np.argmax(sample_probs)

def extract_full_features_from_text(text):
    """
    ä»è¾“å…¥æ–‡æœ¬ä¸­æå–å®Œæ•´çš„1687ç»´ç‰¹å¾å‘é‡ï¼ˆè¿‘ä¼¼ç‰ˆæœ¬ï¼‰
    """
    try:
        # æ–‡æœ¬é¢„å¤„ç†
        processed_text = preprocess_text(text)
        words = processed_text.split()
        word_count = max(len(words), 1)

        # åŠ è½½å¤–éƒ¨è¯å…¸
        hate_words, neg_words, pos_words, ngram_hate_scores = load_external_dictionaries()

        # è®¡æ•°
        hate_count = sum(1 for word in words if word in hate_words)
        neg_count = sum(1 for word in words if word in neg_words)
        pos_count = sum(1 for word in words if word in pos_words)

        # è®¡ç®—ä»‡æ¨å¼ºåº¦ - æ”¹è¿›ç‰ˆï¼Œæ›´å¥½åœ°è¯†åˆ«æ˜ç¡®çš„ä»‡æ¨è¨€è®º
        hate_density = hate_count / word_count if word_count > 0 else 0
        hate_intensity = hate_density

        # å¢å¼ºæƒé‡è®¡ç®— - æ›´ç»†ç²’åº¦çš„åˆ†ç±»
        racial_words = {'nigger', 'nigga', 'kike', 'chink', 'gook', 'spic', 'wetback', 'coon', 'paki', 'raghead', 'towelhead', 'jew', 'arab', 'muslim', 'black', 'white', 'asian', 'hispanic', 'latino', 'mexican', 'african', 'european'}
        strong_racial_words = {'nigger', 'nigga', 'kike', 'coon', 'chink', 'gook', 'spic'}  # ç‰¹åˆ«å¼ºçƒˆçš„ç§æ—æ­§è§†è¯

        gender_words = {'bitch', 'cunt', 'whore', 'slut', 'fag', 'faggot', 'dyke', 'tranny', 'shemale'}
        violence_words = {'kill', 'die', 'death', 'murder', 'rape', 'torture', 'exterminate', 'genocide'}
        extreme_words = {'holocaust', 'nazi', 'hitler', 'supremacist'}  # æç«¯ä¸»ä¹‰è¯æ±‡

        # è®¡ç®—å„ç§ç±»åˆ«çš„è¯é¢‘
        racial_count = sum(1 for word in words if word in racial_words)
        strong_racial_count = sum(1 for word in words if word in strong_racial_words)
        gender_count = sum(1 for word in words if word in gender_words)
        violence_count = sum(1 for word in words if word in violence_words)
        extreme_count = sum(1 for word in words if word in extreme_words)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¼ºçƒˆçš„ä»‡æ¨è¡¨è¾¾
        has_hate_verb = any(word in ['hate', 'deserve', 'kill', 'exterminate', 'genocide'] for word in words)
        has_quantifier = any(word in ['all', 'every', 'each', 'none', 'no'] for word in words)

        # æ£€æŸ¥æ€§åˆ«æ­§è§†æ¨¡å¼
        gender_bias_indicators = [
            'kitchen', 'cooking', 'cleaning', 'housewife', 'homemaker',
            'traditional', 'submissive', 'place', 'role', 'stay'
        ]
        has_gender_bias = any(word in gender_bias_indicators for word in words)
        has_should = 'should' in words
        has_women = 'women' in words or 'woman' in words

        # æ€§åˆ«æ­§è§†ç»„åˆå¾—åˆ†
        gender_bias_score = 0
        if has_gender_bias and has_should and has_women:
            gender_bias_score = 2.0  # å¼ºçƒˆçš„æ€§åˆ«æ­§è§†æ¨¡å¼
        elif has_gender_bias and has_women:
            gender_bias_score = 1.5  # ä¸­ç­‰æ€§åˆ«æ­§è§†
        elif has_gender_bias:
            gender_bias_score = 0.8  # è½»å¾®æ€§åˆ«æ­§è§†

        # åº”ç”¨æƒé‡ - æ›´å¼ºçš„æƒé‡ç³»ç»Ÿ
        if strong_racial_count > 0:
            hate_intensity *= 3.0  # å¼ºçƒˆç§æ—æ­§è§†è¯æƒé‡æœ€é«˜
        elif racial_count > 0:
            hate_intensity *= 2.5  # ä¸€èˆ¬ç§æ—æ­§è§†è¯ä¹Ÿç»™é«˜æƒé‡

        if gender_count > 0:
            hate_intensity *= 1.8  # æ€§åˆ«æ­§è§†æƒé‡

        # åŠ å…¥æ€§åˆ«æ­§è§†å¾—åˆ†
        if gender_bias_score > 0:
            hate_intensity += gender_bias_score

        if violence_count > 0:
            hate_intensity *= 2.5  # æš´åŠ›ç›¸å…³æƒé‡

        if extreme_count > 0:
            hate_intensity *= 3.5  # æç«¯ä¸»ä¹‰è¯æ±‡æƒé‡æœ€é«˜

        # ç»„åˆæ•ˆåº” - å¦‚æœåŒæ—¶åŒ…å«ä»‡æ¨åŠ¨è¯å’Œç¾¤ä½“è¯ï¼Œæ˜¾è‘—æé«˜æƒé‡
        if has_hate_verb and (racial_count > 0 or gender_count > 0):
            hate_intensity *= 1.8  # æ˜ç¡®çš„ä»‡æ¨è¡¨è¾¾

        if has_quantifier and has_hate_verb:
            hate_intensity *= 1.5  # "all", "every"ç­‰é‡åŒ–è¯+ä»‡æ¨åŠ¨è¯

        # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæœ‰å¤šä¸ªä»‡æ¨æŒ‡æ ‡ï¼Œé¢å¤–æå‡
        indicator_count = sum([racial_count > 0, gender_count > 0, violence_count > 0, has_hate_verb, has_quantifier])
        if indicator_count >= 3:
            hate_intensity *= 1.3  # å¤šé‡ä»‡æ¨æŒ‡æ ‡

        # ç¡®ä¿hate_intensityä¸ä¼šè¶…è¿‡åˆç†èŒƒå›´
        hate_intensity = min(hate_intensity, 5.0)  # æœ€å¤§å€¼ä¸º5.0

        # åˆå§‹åŒ–ç‰¹å¾å‘é‡
        features = []

        # 1. weighted_TFIDF_scores
        features.append(hate_intensity)

        # 2. sentiment features (6ä¸ª)
        features.extend([
            hate_count,  # sentiment:hate
            hate_intensity,  # sentiment:hatenor
            neg_count,   # sentiment:neg
            neg_count / word_count if word_count > 0 else 0,  # sentiment:negnor
            pos_count,   # sentiment:pos
            pos_count / word_count if word_count > 0 else 0,  # sentiment:posnor
        ])

        # 3. dependency features (40ä¸ªï¼Œè®¾ä¸º0)
        features.extend([0] * 40)

        # 4. char_bigrams (984ä¸ª) - ç®€åŒ–ä¸ºå­—ç¬¦äºŒå…ƒç»„é¢‘ç‡
        char_bigrams = {}
        for i in range(len(processed_text) - 1):
            bigram = processed_text[i:i+2]
            char_bigrams[bigram] = char_bigrams.get(bigram, 0) + 1

        # æŒ‰å­—æ¯é¡ºåºæ’åºå¹¶å¡«å……åˆ°984ç»´
        sorted_bigrams = sorted(char_bigrams.items())
        for bigram, count in sorted_bigrams[:984]:
            features.append(count)
        # å¡«å……å‰©ä½™çš„ç‰¹å¾ä¸º0
        while len(features) < 1 + 6 + 40 + 984:
            features.append(0)

        # 5. word_bigrams (101ä¸ª) - ç®€åŒ–ä¸ºè¯è¯­äºŒå…ƒç»„é¢‘ç‡
        word_bigrams = {}
        for i in range(len(words) - 1):
            bigram = f"{words[i]}_{words[i+1]}"
            word_bigrams[bigram] = word_bigrams.get(bigram, 0) + 1

        sorted_word_bigrams = sorted(word_bigrams.items())
        for bigram, count in sorted_word_bigrams[:101]:
            features.append(count)
        # å¡«å……å‰©ä½™çš„ç‰¹å¾ä¸º0
        while len(features) < 1 + 6 + 40 + 984 + 101:
            features.append(0)

        # 6. tfidf features (555ä¸ª) - ç®€åŒ–ä¸ºåŸºäºè¯é¢‘çš„ç‰¹å¾
        word_freq = Counter(words)
        # æŒ‰è¯é¢‘æ’åºçš„è¯ä½œä¸ºç‰¹å¾
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        for word, freq in sorted_words[:555]:
            features.append(freq)
        # å¡«å……å‰©ä½™çš„ç‰¹å¾ä¸º0
        while len(features) < 1687:
            features.append(0)

        # ç¡®ä¿ç‰¹å¾æ•°é‡æ­£ç¡®
        if len(features) > 1687:
            features = features[:1687]

        return np.array(features).reshape(1, -1), processed_text

    except Exception as e:
        print(f"ç‰¹å¾æå–å¤±è´¥: {e}")
        return None, None

def preprocess_text(text):
    """
    æ–‡æœ¬é¢„å¤„ç†ï¼Œä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    """
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower()
    # ç§»é™¤URLå’Œ@mentions
    text = re.sub(r"(\w+:\/\/\S+)|(@[A-Za-z0-9]+)", " ", text)
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä¿ç•™å­—æ¯å’Œæ•°å­—
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    text = ' '.join(text.split())
    return text

def predict_from_sentence(sentence: str):
    """
    è¾“å…¥ï¼šåŸå§‹å¥å­
    è¾“å‡ºï¼šé¢„æµ‹æ ‡ç­¾å’Œæ¯ç±»æ¦‚ç‡
    ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–é‡å¤æŸ¥è¯¢
    """
    if not sentence.strip():
        return {"error": "è¯·è¾“å…¥æœ‰æ•ˆçš„å¥å­"}

    # æ£€æŸ¥ç¼“å­˜
    cache_key = sentence.strip().lower()
    if cache_key in prediction_cache:
        cached_result = prediction_cache[cache_key].copy()
        cached_result["input_sentence"] = sentence  # ä¿æŒåŸå§‹å¥å­æ ¼å¼
        return cached_result

    try:
        # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼‰
        load_artifacts()

        # ä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è®­ç»ƒæ ·æœ¬ç‰¹å¾
        features = find_similar_sample_features(sentence)
        features = features.reshape(1, -1)

        if features.shape[1] != len(feature_columns):
            return {"error": f"ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ› {len(feature_columns)} ä¸ªç‰¹å¾ï¼Œå¾—åˆ° {features.shape[1]} ä¸ª"}

        # Scale features
        features_scaled = scaler.transform(features)

        # Convert to tensor and predict
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        tensor = torch.FloatTensor(features_scaled).to(device)
        with torch.no_grad():
            outputs = model(tensor)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()

            # åº”ç”¨ä¼˜åŒ–é˜ˆå€¼æˆ–ä½¿ç”¨é»˜è®¤é¢„æµ‹
            if optimal_thresholds is not None:
                pred_idx = predict_with_optimized_thresholds(probs[0], optimal_thresholds)
            else:
                pred_idx = int(np.argmax(probs, axis=1)[0])
            probs = probs.flatten()

        # Map to label names
        labels = [label_map[str(i)] for i in range(len(probs))]
        result = {
            "prediction": label_map[str(pred_idx)],
            "probabilities": dict(zip(labels, probs.round(4).tolist())),
            "input_sentence": sentence,
            "confidence": float(probs[pred_idx])
        }

        # ç¼“å­˜ç»“æœ
        if len(prediction_cache) >= CACHE_MAX_SIZE:
            # ç®€å•çš„LRUï¼šç§»é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = next(iter(prediction_cache))
            del prediction_cache[oldest_key]
        prediction_cache[cache_key] = result.copy()

        return result

    except Exception as e:
        return {"error": f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"}

def load_external_dictionaries():
    """
    åŠ è½½å¤–éƒ¨è¯å…¸æ–‡ä»¶
    """
    hate_words = set()
    neg_words = set()
    pos_words = set()
    ngram_hate_scores = {}

    try:
        # åŠ è½½ä»‡æ¨è¯å…¸
        if os.path.exists('dictionary/hatebase_dict.csv'):
            with open('dictionary/hatebase_dict.csv', 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip().strip('"\',')
                    if line:
                        hate_words.add(line.lower())

        # åŠ è½½è´Ÿé¢è¯å…¸
        if os.path.exists('dictionary/negative-word.csv'):
            with open('dictionary/negative-word.csv', 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    word = line.strip().lower()
                    if word and word != 'dic':
                        neg_words.add(word)

        # åŠ è½½æ­£é¢è¯å…¸
        if os.path.exists('dictionary/Postive-words.csv'):
            with open('dictionary/Postive-words.csv', 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    word = line.strip().lower()
                    if word and word != 'dic':
                        pos_words.add(word)

        # åŠ è½½n-gramä»‡æ¨åˆ†æ•°
        if os.path.exists('dictionary/refined_ngram_dict.csv'):
            with open('dictionary/refined_ngram_dict.csv', 'r', encoding='utf-8', errors='ignore') as f:
                next(f)  # è·³è¿‡æ ‡é¢˜è¡Œ
                for line in f:
                    parts = line.strip().split(',')
                    if len(parts) >= 2:
                        ngram = parts[0].lower()
                        try:
                            score = float(parts[1])
                            ngram_hate_scores[ngram] = score
                        except ValueError:
                            continue

        print(f"åŠ è½½å®Œæˆ: {len(hate_words)}ä¸ªä»‡æ¨è¯, {len(neg_words)}ä¸ªè´Ÿé¢è¯, {len(pos_words)}ä¸ªæ­£é¢è¯, {len(ngram_hate_scores)}ä¸ªn-gramåˆ†æ•°")

    except Exception as e:
        print(f"åŠ è½½è¯å…¸å¤±è´¥: {e}")
        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯å…¸
        hate_words = {'hate', 'kill', 'nigger', 'faggot', 'bitch', 'fuck', 'shit', 'asshole'}
        neg_words = {'bad', 'worst', 'terrible', 'awful', 'horrible', 'suck', 'angry', 'sad', 'ugly', 'stupid'}
        pos_words = {'good', 'great', 'awesome', 'love', 'happy', 'nice', 'beautiful', 'excellent', 'amazing', 'wonderful'}

    return hate_words, neg_words, pos_words, ngram_hate_scores

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨è®­ç»ƒæ•°æ®ç‰¹å¾ï¼ˆç”¨äºç›¸ä¼¼åº¦åŒ¹é…ï¼‰
training_features = None
training_labels = None
training_texts = None

def load_training_data():
    """
    åŠ è½½è®­ç»ƒæ•°æ®ç‰¹å¾ï¼Œç”¨äºç›¸ä¼¼åº¦åŒ¹é…
    """
    global training_features, training_labels, training_texts

    if training_features is not None:
        return  # å·²åŠ è½½

    try:
        print("åŠ è½½è®­ç»ƒæ•°æ®ç‰¹å¾ç”¨äºç›¸ä¼¼åº¦åŒ¹é…...")

        # åŠ è½½æ‰€æœ‰ç‰¹å¾æ–‡ä»¶
        labels_df = pd.read_csv('test_feature_dataset/labels.csv', encoding='utf-8')
        tfidf_scores = pd.read_csv('test_feature_dataset/tfidf_scores.csv', encoding='utf-8')
        sentiment_scores = pd.read_csv('test_feature_dataset/sentiment_scores.csv', encoding='utf-8')
        dependency_features = pd.read_csv('test_feature_dataset/dependency_features.csv', encoding='utf-8')
        char_bigrams = pd.read_csv('test_feature_dataset/char_bigram_features.csv', encoding='utf-8')
        word_bigrams = pd.read_csv('test_feature_dataset/word_bigram_features.csv', encoding='utf-8')
        tfidf_sparse_matrix = pd.read_csv('test_feature_dataset/tfidf_features.csv', encoding='utf-8')

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        df_list = [labels_df, tfidf_scores, sentiment_scores, dependency_features,
                   char_bigrams, word_bigrams, tfidf_sparse_matrix]
        master = df_list[0]
        for df in df_list[1:]:
            master = master.merge(df, on='index')

        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        training_labels = master.iloc[:, 2].values  # classåˆ—
        training_features = master.iloc[:, 3:].values  # ç‰¹å¾åˆ—
        training_texts = master.iloc[:, 1].values  # tweetåˆ—

        print(f"è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆ: {training_features.shape[0]} ä¸ªæ ·æœ¬, {training_features.shape[1]} ä¸ªç‰¹å¾")

    except Exception as e:
        print(f"åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
        training_features = None
        training_labels = None
        training_texts = None

def find_similar_sample_features(input_text: str):
    """
    æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è®­ç»ƒæ ·æœ¬ï¼Œè¿”å›å…¶ç‰¹å¾å‘é‡
    ä½¿ç”¨æ”¹è¿›çš„ç›¸ä¼¼åº¦è®¡ç®—å’Œç±»åˆ«å¹³è¡¡
    """
    global training_features, training_labels, training_texts

    if training_features is None:
        load_training_data()

    if training_features is None:
        # å¦‚æœæ— æ³•åŠ è½½è®­ç»ƒæ•°æ®ï¼Œè¿”å›é›¶å‘é‡
        return np.zeros(1687)

    try:
        # é¢„å¤„ç†è¾“å…¥æ–‡æœ¬
        input_text = preprocess_text(input_text)
        input_words = set(input_text.split())

        # è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„ç›¸ä¼¼åº¦
        similarities = []

        for i, train_text in enumerate(training_texts):
            if pd.isna(train_text):
                continue

            train_text_processed = preprocess_text(str(train_text))
            train_words = set(train_text_processed.split())

            # è®¡ç®—Jaccardç›¸ä¼¼åº¦ (äº¤é›†/å¹¶é›†)
            intersection = len(input_words.intersection(train_words))
            union = len(input_words.union(train_words))

            if union > 0:
                jaccard_similarity = intersection / union
            else:
                jaccard_similarity = 0

            similarities.append((jaccard_similarity, i))

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(reverse=True, key=lambda x: x[0])

        # æ™ºèƒ½é€‰æ‹©æ ·æœ¬ï¼šåŸºäºå†…å®¹ç‰¹å¾è¿›è¡Œç±»åˆ«åå¥½
        input_text_lower = input_text.lower()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ€§åˆ«æ­§è§†æŒ‡æ ‡
        gender_bias_keywords = ['women', 'woman', 'kitchen', 'stay', 'should', 'place', 'traditional', 'role']
        has_gender_bias = any(keyword in input_text_lower for keyword in gender_bias_keywords)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«è´Ÿé¢è¯æ±‡
        negative_keywords = ['hate', 'stupid', 'idiot', 'dumb', 'asshole', 'fuck', 'shit', 'bitch']
        has_negative = any(keyword in input_text_lower for keyword in negative_keywords)

        # æ ¹æ®å†…å®¹ç‰¹å¾é€‰æ‹©åå¥½çš„ç±»åˆ«
        preferred_class = None
        if has_gender_bias or has_negative:
            preferred_class = 1  # offensive_language
        elif len(input_text.split()) > 3:  # è¾ƒé•¿çš„å¥å­å€¾å‘äºneither
            preferred_class = 2  # neither

        # é€‰æ‹©æœ€ä½³æ ·æœ¬
        best_sample_idx = similarities[0][1]  # é»˜è®¤é€‰æ‹©æœ€ç›¸ä¼¼çš„

        # å¦‚æœæœ‰åå¥½ç±»åˆ«ï¼Œå¯»æ‰¾ç›¸ä¼¼åº¦>0.05çš„è¯¥ç±»åˆ«æ ·æœ¬
        if preferred_class is not None:
            for similarity, idx in similarities[:100]:  # æ£€æŸ¥å‰100ä¸ªæœ€ç›¸ä¼¼çš„
                if similarity > 0.05 and training_labels[idx] == preferred_class:
                    best_sample_idx = idx
                    print(f"åŸºäºå†…å®¹ç‰¹å¾é€‰æ‹©ç±»åˆ« {preferred_class} çš„æ ·æœ¬ (ç›¸ä¼¼åº¦: {similarity:.3f})")
                    break

        # è¿”å›æœ€ç›¸ä¼¼æ ·æœ¬çš„ç‰¹å¾
        return training_features[best_sample_idx]

    except Exception as e:
        print(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
        # è¿”å›"neither"ç±»åˆ«çš„å¹³å‡ç‰¹å¾å‘é‡
        neither_mask = training_labels == 2
        if np.any(neither_mask):
            return np.mean(training_features[neither_mask], axis=0)
        else:
            return np.mean(training_features, axis=0)

def create_prediction_visualization(result):
    """
    åˆ›å»ºé¢„æµ‹ç»“æœçš„å¯è§†åŒ–å›¾è¡¨
    """
    if isinstance(result, dict) and 'error' not in result:
        # è·å–é¢„æµ‹ç»“æœ
        prediction = result.get('prediction', 'unknown')
        probabilities = result.get('probabilities', {})
        confidence = result.get('confidence', 0)

        # åˆ›å»ºæ¡å½¢å›¾
        labels = list(probabilities.keys())
        values = list(probabilities.values())

        # åˆ›å»ºé¢œè‰²æ˜ å°„
        colors = []
        for label in labels:
            if label == prediction:
                colors.append('#FF6B6B')  # çº¢è‰²çªå‡ºæ˜¾ç¤ºé¢„æµ‹ç»“æœ
            else:
                colors.append('#4ECDC4')  # é’è‰²ç”¨äºå…¶ä»–ç±»åˆ«

        # ä½¿ç”¨plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨
        fig = go.Figure(data=[
            go.Bar(
                x=labels,
                y=values,
                marker_color=colors,
                text=[f'{v:.3f}' for v in values],
                textposition='auto',
            )
        ])

        fig.update_layout(
            title={
                'text': f'ä»‡æ¨è¨€è®ºæ£€æµ‹ç»“æœ - é¢„æµ‹: {prediction} (ç½®ä¿¡åº¦: {confidence:.3f})',
                'y':0.95,
                'x':0.5,
                'xanchor': 'center',
                'yanchor': 'top'
            },
            xaxis_title="ç±»åˆ«",
            yaxis_title="æ¦‚ç‡",
            xaxis_tickangle=-45,
            height=400,
            margin=dict(l=20, r=20, t=60, b=20)
        )

        # æ·»åŠ é¢„æµ‹ç±»åˆ«çš„é«˜äº®çº¿
        if prediction in probabilities:
            pred_prob = probabilities[prediction]
            fig.add_hline(
                y=pred_prob,
                line_dash="dash",
                line_color="red",
                annotation_text=f"é¢„æµ‹ç»“æœ: {prediction}",
                annotation_position="top right"
            )

        return fig
    else:
        # é”™è¯¯æƒ…å†µ
        fig = go.Figure()
        fig.add_annotation(
            text="é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥",
            xref="paper", yref="paper",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=20, color="red")
        )
        fig.update_layout(
            title="é¢„æµ‹é”™è¯¯",
            height=400
        )
        return fig

def predict_from_features(feature_csv_line: str):
    """
    è¾“å…¥ï¼šä¸€è¡Œä»¥é€—å·åˆ†éš”çš„æ•°å€¼ï¼ˆä¸ feature_columns é¡ºåºä¸€è‡´ï¼‰
    è¾“å‡ºï¼šé¢„æµ‹æ ‡ç­¾å’Œæ¯ç±»æ¦‚ç‡
    """
    try:
        parts = [float(x.strip()) for x in feature_csv_line.split(',')]
    except Exception as e:
        return {"error": f"æ— æ³•è§£æè¾“å…¥ä¸ºæ•°å€¼å‘é‡: {e}"}
    arr = np.array(parts).reshape(1, -1)
    if arr.shape[1] != len(feature_columns):
        return {"error": f"ç‰¹å¾æ•°ä¸åŒ¹é…: æœŸæœ› {len(feature_columns)} ä¸ªç‰¹å¾ï¼Œæ”¶åˆ° {arr.shape[1]} ä¸ªã€‚"}

    # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼‰
    load_artifacts()

    arr_scaled = scaler.transform(arr)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    tensor = torch.FloatTensor(arr_scaled).to(device)
    with torch.no_grad():
        outputs = model(tensor)
        probs = torch.softmax(outputs, dim=1).cpu().numpy().flatten()
        pred_idx = int(torch.argmax(outputs, dim=1).cpu().numpy()[0])
    # map to label names
    labels = [label_map[str(i)] for i in range(len(probs))]
    result = {
        "prediction": label_map[str(pred_idx)],
        "probabilities": dict(zip(labels, probs.round(4).tolist())),
        "confidence": float(probs[pred_idx])
    }
    return result

def show_feature_columns():
    return "Please provide a comma-separated numeric feature vector matching the following columns (order matters):\n\n" + ", ".join(feature_columns)


# å®šä¹‰MLPNetç±»ï¼ˆç”¨äºåŠ è½½æ¨¡å‹ï¼‰
class MLPNet(torch.nn.Module):
    def __init__(self, input_dim, hidden_dims=[80, 40, 40, 10], num_classes=3, dropout=0.1):
        super(MLPNet, self).__init__()
        layers = []
        prev_dim = input_dim

        for hidden_dim in hidden_dims:
            layers.append(torch.nn.Linear(prev_dim, hidden_dim))
            layers.append(torch.nn.ReLU())
            layers.append(torch.nn.Dropout(dropout))
            prev_dim = hidden_dim

        layers.append(torch.nn.Linear(prev_dim, num_classes))
        self.network = torch.nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

with gr.Blocks() as demo:
    gr.Markdown("# ä»‡æ¨è¨€è®ºæ£€æµ‹ç³»ç»Ÿ / Hate Speech Detection System")

    with gr.Tab("å¥å­è¾“å…¥ (Sentence Input)"):
        gr.Markdown("### ç›´æ¥è¾“å…¥å¥å­è¿›è¡Œæ£€æµ‹ / Enter a sentence for detection")
        gr.Markdown("**âœ¨ æ¨èä½¿ç”¨** - ç³»ç»Ÿä¼šè‡ªåŠ¨æå–ç‰¹å¾å¹¶è¿›è¡Œå‡†ç¡®æ£€æµ‹")

        sentence_input = gr.Textbox(
            lines=3,
            placeholder="è¾“å…¥ä¸€å¥è‹±è¯­å¥å­è¿›è¡Œä»‡æ¨è¨€è®ºæ£€æµ‹... / Enter an English sentence to detect hate speech...",
            label="å¥å­ / Sentence"
        )
        predict_sentence_btn = gr.Button("ğŸ” æ£€æµ‹ä»‡æ¨è¨€è®º / Detect Hate Speech")

        with gr.Row():
            with gr.Column(scale=1):
                sentence_output = gr.JSON(label="è¯¦ç»†ç»“æœ / Detailed Results")

            with gr.Column(scale=2):
                visualization_output = gr.Plot(label="é¢„æµ‹å¯è§†åŒ– / Prediction Visualization")

        predict_sentence_btn.click(
            fn=predict_from_sentence,
            inputs=sentence_input,
            outputs=sentence_output
        ).then(
            fn=create_prediction_visualization,
            inputs=sentence_output,
            outputs=visualization_output
        )

    with gr.Tab("ç‰¹å¾å‘é‡è¾“å…¥ (Feature Vector Input)"):
        gr.Markdown("### è¾“å…¥ç‰¹å¾å‘é‡ / Provide feature vector")
        gr.Markdown("""
        **â­ æ¨èä½¿ç”¨æ­¤æ–¹æ³•è·å¾—æœ€å‡†ç¡®çš„ç»“æœï¼â­**
        *å¦‚æœæ‚¨æœ‰é¢„è®¡ç®—çš„ç‰¹å¾å‘é‡ï¼Œå¯ä»¥ç›´æ¥è¾“å…¥ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰*

        **é‡è¦æç¤º**ï¼šè¦å‡†ç¡®æ£€æµ‹ä»‡æ¨è¨€è®ºï¼Œè¯·ä½¿ç”¨æ­¤é€‰é¡¹æä¾›å®Œæ•´çš„ç‰¹å¾å‘é‡ã€‚
        """)
        with gr.Row():
            feature_input = gr.Textbox(
                lines=3,
                placeholder="e.g. 0.12, 1.0, 0.0, ... (éœ€è¦1687ä¸ªç‰¹å¾å€¼)",
                label="ç‰¹å¾å‘é‡ (CSVæ ¼å¼) / Feature vector (CSV format)"
            )
            info_btn = gr.Button("æŸ¥çœ‹ç‰¹å¾åˆ—é¡ºåº / Show feature columns")
        predict_features_btn = gr.Button("é¢„æµ‹ / Predict")
        features_output = gr.JSON()

        predict_features_btn.click(
            fn=predict_from_features,
            inputs=feature_input,
            outputs=features_output
        )
        info_btn.click(
            fn=show_feature_columns,
            inputs=None,
            outputs=features_output
        )

    gr.Markdown("""
    ### ä½¿ç”¨è¯´æ˜ / Instructions:

    #### ğŸ¯ **å¥å­è¾“å…¥ (æ¨èæ–°åŠŸèƒ½)**
    - âœ¨ **è‡ªåŠ¨ç‰¹å¾æå–**: ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„1687ç»´ç‰¹å¾å‘é‡
    - ğŸ¨ **å¯è§†åŒ–ç»“æœ**: äº¤äº’å¼æ¦‚ç‡åˆ†å¸ƒå›¾è¡¨ï¼Œç›´è§‚å±•ç¤ºé¢„æµ‹ç»“æœ
    - âš¡ **å®æ—¶æ£€æµ‹**: è¾“å…¥æ–‡æœ¬åç«‹å³è·å¾—å‡†ç¡®çš„ä»‡æ¨è¨€è®ºæ£€æµ‹ç»“æœ

    #### ğŸ”§ **ç‰¹å¾å‘é‡è¾“å…¥ (ä¸“ä¸šæ¨¡å¼)**
    - â­ **æœ€é«˜å‡†ç¡®æ€§**: å¦‚æœæ‚¨æœ‰é¢„å¤„ç†çš„ç‰¹å¾å‘é‡ï¼Œå¯ä»¥ç›´æ¥è¾“å…¥
    - ğŸ¯ **å®Œæ•´ç‰¹å¾**: ä½¿ç”¨è®­ç»ƒæ—¶çš„å®Œæ•´1687ç»´ç‰¹å¾

    #### ğŸ“Š **è¾“å‡ºè¯´æ˜**
    - `prediction`: é¢„æµ‹ç±»åˆ« (hate_speech / offensive_language / neither)
    - `probabilities`: å„ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
    - `confidence`: å¯¹é¢„æµ‹ç»“æœçš„ç½®ä¿¡åº¦
    - **å¯è§†åŒ–å›¾è¡¨**: å½©è‰²æ¡å½¢å›¾æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒï¼Œçº¢è‰²çªå‡ºé¢„æµ‹ç»“æœ

    #### ğŸ’¡ **ä½¿ç”¨å»ºè®®**
    - ğŸ¥‡ **æ¨è**: ä½¿ç”¨"å¥å­è¾“å…¥"ä½“éªŒå®Œæ•´åŠŸèƒ½å’Œå¯è§†åŒ–
    - ğŸ¥ˆ **æ‰¹é‡å¤„ç†**: å‘½ä»¤è¡Œå·¥å…· `python main/extract_features.py text "æ–‡æœ¬"` æ‰¹é‡æå–ç‰¹å¾
    - ğŸ¥‰ **ä¸“ä¸šåº”ç”¨**: "ç‰¹å¾å‘é‡è¾“å…¥"ç”¨äºæœ€é«˜å‡†ç¡®æ€§éœ€æ±‚

    #### ğŸš€ **å¿«é€Ÿæµ‹è¯•ç¤ºä¾‹**
    è¯•è¯•è¾“å…¥è¿™äº›å¥å­çœ‹çœ‹æ•ˆæœï¼š
    - **ä»‡æ¨è¨€è®º**: "I hate all black people, they are inferior"
    - **å†’çŠ¯è¯­è¨€**: "You are such an asshole"
    - **æ­£å¸¸æ–‡æœ¬**: "The weather is nice today"
    - **æ€§åˆ«æ­§è§†**: "Women should stay in the kitchen"
    """)

if __name__ == "__main__":
    try:
        # å¯åŠ¨æ—¶åŠ è½½artifacts
        load_artifacts()
        print("å¯åŠ¨Gradioç•Œé¢...")
        demo.launch()
    except Exception as e:
        print(f"å¯åŠ¨å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆartifacts: python main/train_final_model.py")
        exit(1)
